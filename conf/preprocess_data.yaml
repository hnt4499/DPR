# extractive reader configuration

defaults:
  - encoder: hf_bert

# Whether to lower case the input text. Set True for uncased models, False for the cased ones.
do_lower_case: True

seed: 42

# glob expression for train data files
train_files: /data/tuyen/openqa/DPR/downloads/data/retriever_results/nq/single-new/train.json

# glob expression for dev data files
dev_files: /data/tuyen/openqa/DPR/downloads/data/retriever_results/nq/single-new/dev.json

# Total amount of positive and negative passages per question
passages_per_question: 8

# Total amount of positive and negative passages per question for evaluation
passages_per_question_predict: 60

# The output directory where the model checkpoints will be written to
output_dir: checkpoints/


# File with the original train dataset passages (json format)
gold_passages_src: /data/tuyen/openqa/DPR/downloads/data/gold_passages_info/nq_train.json

# File with the original dataset passages (json format)
gold_passages_src_dev: /data/tuyen/openqa/DPR/downloads/data/gold_passages_info/nq_dev.json

# Entire tokenized Wikipedia passages (pkl format)
wiki_psgs_tokenized: /data/tuyen/openqa/DPR/downloads/data/wikipedia_split/psgs_w100_tokenized.pkl.*

# BM25 retrieval results (pre-processed; pkl format)
bm25_retrieval_results: /data/tuyen/openqa/DPR/downloads/data/retriever/nq-train.bm25.top100.pkl

# num of threads to pre-process data.
num_workers: 4

# a list of tokens to avoid tokenization
special_tokens:

# Debug
debugging: False