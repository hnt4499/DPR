# extractive reader configuration

defaults:
  - encoder: hf_bert
  - train: extractive_reader_default

# A trained reader checkpoint file to initialize the model
model_file:
resume: True  # whether to resume training; only applicable when `model_file` is specified

# Whether to lower case the input text. Set True for uncased models, False for the cased ones.
do_lower_case: True

seed: 42

# ========================================== TRAIN ==================================================

# glob expression for train data files
train_files: /data/tuyen/openqa/DPR/downloads/data/retriever_results/nq/single-new/train.json
compress: False

# Data iterator type
train_iterator_class: ShardedDataIterator

# File with the original train dataset passages (json format)
gold_passages_src: /data/tuyen/openqa/DPR/downloads/data/gold_passages_info/nq_train.json

# File with the preprocessed (i.e., 100-word) gold passages
gold_passages_processed: /data/tuyen/openqa/DPR/downloads/data/retriever/nq-train.gold.pkl

# BM25 retrieval results (pre-processed; for training data only; pkl format)
bm25_retrieval_results: /data/tuyen/openqa/DPR/downloads/data/retriever/nq-train.bm25.top100.pkl

# =========================================== DEV ===================================================

# glob expression for dev data files
dev_files: /data/tuyen/openqa/DPR/downloads/data/retriever_results/nq/single-new/dev.json

# Data iterator type
dev_iterator_class: ShardedDataIterator

# File with the original dataset passages (json format)
gold_passages_src_dev: /data/tuyen/openqa/DPR/downloads/data/gold_passages_info/nq_dev.json

# File with the preprocessed (i.e., 100-word) gold passages
gold_passages_processed_dev: /data/tuyen/openqa/DPR/downloads/data/retriever/nq-dev.gold.pkl

# ========================================== GENERAL ================================================

# Entire tokenized Wikipedia passages (pkl format)
wiki_psgs_tokenized: /data/tuyen/openqa/DPR/downloads/data/wikipedia_split/psgs_w100_tokenized.pkl.*

# ===================================================================================================

# Total amount of positive and negative passages per question
passages_per_question: 8

# Total amount of positive and negative passages per question for evaluation
passages_per_question_predict: 60

# The output directory where the model checkpoints will be written to
output_dir: checkpoints/

# Max amount of answer spans to marginalize per singe passage
max_n_answers: 10

# The maximum length of an answer that can be generated. This is needed because the start
# and end predictions are not conditioned on one another
max_answer_length: 10

# Top **retrieval** passages thresholds to analyze prediction results for; this should be equal to `passages_per_question_predict`
eval_top_docs:
  - 50

checkpoint_file_name: dpr_extractive_reader

# Path to a file to write prediction results to
prediction_results_file:

# Enables fully resumable mode
fully_resumable: True

# num of threads to pre-process data.
num_workers: 4

# TODO: move to a conf group
# local_rank for distributed training on gpus
local_rank: -1
global_loss_buf_sz: 150000
device:
distributed_world_size:
no_cuda: False
n_gpu:
fp16: False

# For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3']."
#        "See details at https://nvidia.github.io/apex/amp.html
fp16_opt_level: O1

# Gradient checkpointing settings
gradient_checkpointing: False

# a list of tokens to avoid tokenization
special_tokens:

# Debug
debugging: False
