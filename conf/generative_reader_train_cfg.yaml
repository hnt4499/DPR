# Generative reader configuration
defaults:
  - train: generative_reader_default
  - encoder: fid_base

# A trained reader checkpoint file to initialize the model
model_file:
seed: 42


# glob expression for train data files
train_files: /data/tuyen/openqa/DPR/downloads/data/retriever_results/nq/single-t5/train.json

# Data iterator type
train_iterator_class: ShardedDataIterator

# glob expression for dev data files
dev_files: /data/tuyen/openqa/DPR/downloads/data/retriever_results/nq/single-t5/dev.json

# Data iterator type
dev_iterator_class: ShardedDataIterator

# Entire tokenized Wikipedia passages (pkl format)
wiki_psgs_tokenized: /data/tuyen/openqa/DPR/downloads/data/wikipedia_split_t5/psgs_w100_tokenized.pkl.*

# Total amount of positive and negative passages per question
passages_per_question: 100

# Total amount of positive and negative passages per question for evaluation
passages_per_question_predict: 100

# The output directory where the model checkpoints will be written to
output_dir: checkpoints/

checkpoint_file_name: dpr_generative_reader

# Path to a file to write prediction results to
prediction_results_file: predictions.json

# Enables fully resumable mode
fully_resumable: True

# num of threads to pre-process data.
num_workers: 4

# TODO: move to a conf group
# local_rank for distributed training on gpus
local_rank: -1
global_loss_buf_sz: 150000
device:
distributed_world_size:
no_cuda: False
n_gpu:
fp16: False

# For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3']."
#        "See details at https://nvidia.github.io/apex/amp.html
fp16_opt_level: O1

# Gradient checkpointing settings
gradient_checkpointing: True

# a list of tokens to avoid tokenization
special_tokens:

# Debug
debugging: False